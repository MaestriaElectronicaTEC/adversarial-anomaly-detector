{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacial variational autoencoder for anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from random import seed\n",
    "from random import randint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.misc\n",
    "from scipy.misc import imsave\n",
    "from progressbar import ETA, Bar, Percentage, ProgressBar\n",
    "from vae import VAE\n",
    "import time\n",
    "from imutils import paths\n",
    "from keras.utils. generic_utils import Progbar\n",
    "from ops import *\n",
    "flags = tf.flags\n",
    "logging = tf.logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(img):\n",
    "    return (img.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "# load tomato images\n",
    "def load_real_samples():\n",
    "    # folder where data is placed\n",
    "    BASE_FOLDER = '/floyd/input/tomato_dataset/training'\n",
    "    \n",
    "    trainAug = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            zoom_range=0.05,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            shear_range=0.05,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            fill_mode=\"nearest\",\n",
    "            preprocessing_function=normalize_data)\n",
    "    \n",
    "    trainGen = trainAug.flow_from_directory(\n",
    "            BASE_FOLDER,\n",
    "            class_mode=\"input\",\n",
    "            target_size=(48, 48),\n",
    "            color_mode=\"rgb\",\n",
    "            shuffle=True,\n",
    "            batch_size=64)\n",
    "    \n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(filename):\n",
    "  filename_without_format = filename[:-4]\n",
    "  filename_list = filename_without_format.split('_')\n",
    "  coordinates_list = filename_list[-1].split('x')\n",
    "  for item in range(len(coordinates_list)):\n",
    "    coordinates_list[item] = int(coordinates_list[item])\n",
    "  return coordinates_list\n",
    "\n",
    "def load_test_data():\n",
    "    # folder where data is placed\n",
    "    BASE_FOLDER = '/floyd/input/tomato_dataset/testing/2019-09-19_06_47_32/'\n",
    "    img_list = glob.glob(BASE_FOLDER + '*.png')\n",
    "    images = list()\n",
    "    coordinates = list()\n",
    "    \n",
    "    for img_path in img_list:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (48, 48), interpolation = cv2.INTER_NEAREST)\n",
    "        img = (img.astype(np.float32) - 127.5) / 127.5\n",
    "        images.append(img)\n",
    "        position = get_coordinates(img_path)\n",
    "        coordinates.append(position)\n",
    "        \n",
    "    print('Found ' + str(len(images)) + ' images for test.')\n",
    "    return (np.asarray(images), coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # get batch\n",
    "    X, _ = dataset.next()\n",
    "    # choose random instances\n",
    "    ix = randint(0, X.shape[0], n_samples)\n",
    "    # select images\n",
    "    X = X[ix]\n",
    "    # generate class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_test_samples(X, n_samples):\n",
    "    # choose random instances\n",
    "    ix = randint(0, X.shape[0], n_samples)\n",
    "    # select images\n",
    "    X = X[ix]\n",
    "    # generate class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "test_dataset, test_coordinates = load_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "batch_size = 32\n",
    "updates_per_epoch = 1600\n",
    "max_epoch = 2000\n",
    "max_test_epoch = 100\n",
    "learning_rate = 1e-4\n",
    "working_directory = \"/floyd/home/models/svae\"\n",
    "hidden_size = 2\n",
    "channel = 96\n",
    "checkpoint = 1450\n",
    "model_name = \"low_rank\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(hidden_size, batch_size, learning_rate, channel, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epoch): \n",
    "    training_loss = 0.0\n",
    "    print('epoch', epoch)\n",
    "    progress_bar = Progbar(target=updates_per_epoch)\n",
    "    t_start= time.clock()\n",
    "    for i in range(updates_per_epoch):\n",
    "        images, _ = generate_real_samples(dataset, batch_size)\n",
    "        loss_value, kl_loss, rec_loss = model.update_params(images, epoch*updates_per_epoch + i)\n",
    "        training_loss += loss_value\n",
    "        progress_bar.update(i, values=[('loss_value', loss_value), ('kl_loss', kl_loss), ('rec_loss', rec_loss)])\n",
    "    t_end = time.clock()\n",
    "    print (\"training per epoch time ====== %f\" %(t_end-t_start))\n",
    "    model.save(epoch)\n",
    "    training_loss = training_loss/ (updates_per_epoch * batch_size)\n",
    "    print (\"Loss %f\" % training_loss)\n",
    "    print('')\n",
    "    model.generate_and_save_images(batch_size, working_directory)\n",
    "    dataset.on_epoch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reload(checkpoint)\n",
    "samples= model.generate_samples()\n",
    "sigmas = np.logspace(-1.0, 0.0, 10)\n",
    "lls = []\n",
    "for sigma in sigmas:\n",
    "    print(\"sigma: \", sigma)\n",
    "    nlls =[]\n",
    "    for i in range(1, 10+1):\n",
    "        X = generate_test_samples(test_dataset, batch_size)\n",
    "        nll = parzen_cpu_batch(X, samples, sigma=sigma, batch_size=batch_size, num_of_samples=10000, data_size=12288)\n",
    "        nlls.extend(nll)\n",
    "    nlls = np.array(nlls).reshape(1000) # 1000 valid images\n",
    "    print(\"sigma: \", sigma)\n",
    "    print(\"ll: %d\" % (np.mean(nlls)))\n",
    "    lls.append(np.mean(nlls))\n",
    "sigma = sigmas[np.argmax(lls)]           \n",
    "\n",
    "nlls = []\n",
    "for i in range(1,100+1): # number of test batches = 100\n",
    "    X = generate_test_samples(test_dataset, batch_size)\n",
    "    nll = parzen_cpu_batch(X, samples, sigma=sigma, batch_size=batch_size, num_of_samples=10000, data_size=12288)\n",
    "    nlls.extend(nll)\n",
    "nlls = np.array(nlls).reshape(10000) # 10000 test images\n",
    "print(\"sigma: \", sigma)\n",
    "print(\"ll: %d\" % (np.mean(nlls)))\n",
    "print(\"se: %d\" % (nlls.std() / np.sqrt(10000)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
